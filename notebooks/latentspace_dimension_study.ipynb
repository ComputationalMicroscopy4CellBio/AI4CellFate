{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append(os.path.abspath(\"..\"))  #TODO: MAKE THE SRC PACKAGE WORK\n",
    "from src.training.new_optimised_train import train_autoencoder, train_cellfate\n",
    "from src.evaluation.evaluate import *\n",
    "from src.training.loss_functions import *\n",
    "from src.preprocessing.preprocessing_functions import *\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from src.models import Encoder, Decoder, Discriminator, mlp_classifier, complex_mlp_classifier\n",
    "from src.utils import *\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import tensorflow as tf\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('../data/images/time_norm_train_images.npy')[:,0,:,:]\n",
    "y_train = np.load('../data/labels/train_labels_augmented4.npy')\n",
    "x_test = np.load('../data/images/time_norm_test_images.npy')[:,0,:,:]\n",
    "y_test = np.load('../data/labels/test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.72072072, 0.27927928],\n",
       "        [0.57142857, 0.42857143]],\n",
       "\n",
       "       [[0.67567568, 0.32432432],\n",
       "        [0.25      , 0.75      ]],\n",
       "\n",
       "       [[0.6036036 , 0.3963964 ],\n",
       "        [0.25      , 0.75      ]],\n",
       "\n",
       "       [[0.64864865, 0.35135135],\n",
       "        [0.35714286, 0.64285714]],\n",
       "\n",
       "       [[0.        , 0.        ],\n",
       "        [0.        , 0.        ]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"/Users/inescunha/Documents/GitHub/CellFate/results/data_labelling_study/split_0.9/confusion_matrices_cellfate.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.6036036 , 0.3963964 ],\n",
       "        [0.35714286, 0.64285714]],\n",
       "\n",
       "       [[0.62162162, 0.37837838],\n",
       "        [0.32142857, 0.67857143]],\n",
       "\n",
       "       [[0.61261261, 0.38738739],\n",
       "        [0.35714286, 0.64285714]],\n",
       "\n",
       "       [[0.58558559, 0.41441441],\n",
       "        [0.28571429, 0.71428571]],\n",
       "\n",
       "       [[0.        , 0.        ],\n",
       "        [0.        , 0.        ]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"/Users/inescunha/Documents/GitHub/CellFate/results/data_labelling_study/split_0.9/confusion_matrices_tabular.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "latent_space_dim = [2, 3, 5, 10, 100]\n",
    "\n",
    "for dim in latent_space_dim:\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    confusion_matrices_cellfate = np.zeros((len(dim), 2, 2))\n",
    "\n",
    "    output_dir=f\"../results/ls_dimension_study/dim{dim}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    config_ae = {\n",
    "                'batch_size': 30,\n",
    "                'epochs': 15,\n",
    "                'learning_rate': 0.001,\n",
    "                'seed': seed,\n",
    "                'latent_dim': dim,\n",
    "                'GaussianNoise_std': 0.003,\n",
    "                'lambda_recon': 5,\n",
    "                'lambda_adv': 1,\n",
    "            }\n",
    "\n",
    "    config_cellfate = {\n",
    "        'batch_size': 30,\n",
    "        'epochs': 100,\n",
    "        'learning_rate': 0.001,\n",
    "        'seed': seed,\n",
    "        'latent_dim': dim,\n",
    "        'GaussianNoise_std': 0.003,\n",
    "        'lambda_recon': 6,\n",
    "        'lambda_adv': 4,\n",
    "        'lambda_cov': 0.0001,\n",
    "        'lambda_contra': 8,\n",
    "    }\n",
    "\n",
    "    config_clf = {\n",
    "        'batch_size': 30,\n",
    "        'epochs': 50,\n",
    "        'learning_rate': 0.001,\n",
    "        'seed': seed,\n",
    "        'latent_dim': dim,\n",
    "    }\n",
    "\n",
    "    results_autoencoder = train_autoencoder(config_ae, x_train)\n",
    "    encoder = results_autoencoder['encoder']\n",
    "    decoder = results_autoencoder['decoder']\n",
    "    discriminator = results_autoencoder['discriminator']\n",
    "\n",
    "    # IMAGES: Train AIcellfate with smaller dataset\n",
    "\n",
    "    results_cellfate = train_cellfate(config_cellfate, encoder, decoder, discriminator, x_train, y_train, x_test, y_test) #lambda_recon=scaled_autoencoder_results['lambda_recon'], lambda_adv=scaled_autoencoder_results['lambda_adv']\n",
    "    encoder = results_cellfate['encoder']\n",
    "    decoder = results_cellfate['decoder']\n",
    "    discriminator = results_cellfate['discriminator']\n",
    "\n",
    "    save_model_weights_to_disk(encoder, decoder, discriminator, output_dir=output_dir)\n",
    "\n",
    "    evaluator = Evaluation(output_dir)\n",
    "\n",
    "    # Evaluate the model (and saving everything)\n",
    "    z_imgs = encoder.predict(x_train)\n",
    "    recon_imgs = decoder.predict(z_imgs)\n",
    "    evaluator.reconstruction_images(x_train, recon_imgs[:,:,:,0], epoch=0)\n",
    "    evaluator.visualize_latent_space(z_imgs, y_train, epoch=0)\n",
    "    cov_matrix = cov_loss_terms(z_imgs)[0]\n",
    "    evaluator.plot_cov_matrix(cov_matrix, epoch=0) # the epoch is a placeholder, it doesnt mean anything (TODO: change these functions)\n",
    "\n",
    "    tf.keras.utils.set_random_seed(config_clf['seed'])\n",
    "\n",
    "    classifier = mlp_classifier(latent_dim=config_clf['latent_dim'])\n",
    "    classifier.compile(loss='sparse_categorical_crossentropy', optimizer= tf.keras.optimizers.Adam(learning_rate=config_clf['learning_rate']), metrics=['accuracy'])\n",
    "\n",
    "    x_val, x_test_, y_val, y_test_ = train_test_split(encoder.predict(x_test), y_test, test_size=0.5, random_state=42) \n",
    "    history = classifier.fit(encoder.predict(x_train), y_train, batch_size=config_clf['batch_size'], epochs=config_clf['epochs'], validation_data=(x_val, y_val)) \n",
    "\n",
    "    y_pred = classifier.predict(x_test_)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    num_classes = len(np.unique(y_test_))\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test_, y_pred_classes)\n",
    "\n",
    "    class_sums = cm.sum(axis=1, keepdims=True)\n",
    "    conf_matrix_normalized = cm / class_sums\n",
    "\n",
    "    confusion_matrices_cellfate[latent_space_dim.index(dim)] = conf_matrix_normalized\n",
    "\n",
    "    # Save confusion matrix\n",
    "    plot_confusion_matrix(y_test_, y_pred, num_classes)\n",
    "    np.save(f\"{output_dir}/confusion_matrices_cellfate.npy\", confusion_matrices_cellfate)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models after all the training and check the perturbations\n",
    "\n",
    "baseline_latent_vector = np.zeros((3, 3), dtype=np.float32)  # Start with a neutral latent vector\n",
    "\n",
    "# Choose the feature to perturb (e.g., feature 0)\n",
    "feature_index = 2\n",
    "\n",
    "# Perturbation range\n",
    "perturbations = np.linspace(-3, 2, 5) # feature index 1\n",
    "perturbations = np.linspace(-2.5, 1.5, 5) # feature index 0\n",
    "\n",
    "# Store the perturbed reconstructions\n",
    "perturbed_reconstructions = []\n",
    "\n",
    "for value in perturbations:\n",
    "    # Create a copy of the baseline latent vector\n",
    "    perturbed_vector = baseline_latent_vector.copy()\n",
    "    print(perturbed_vector.shape)\n",
    "    # Modify the selected feature\n",
    "    perturbed_vector[0, feature_index] = value\n",
    "    \n",
    "    # Decode the perturbed vector to generate a synthetic image\n",
    "    synthetic_image = decoder.predict(perturbed_vector)  # Assuming 'decoder' is your trained decoder model\n",
    "    \n",
    "    # Store the result\n",
    "    perturbed_reconstructions.append(synthetic_image[0])  # Assuming decoder outputs (batch_size, height, width, channels)\n",
    "\n",
    "# Convert list to numpy array for easier handling\n",
    "perturbed_reconstructions = np.array(perturbed_reconstructions)\n",
    "\n",
    "# Plot the results\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20, 4))\n",
    "vmin = perturbed_reconstructions.min()\n",
    "vmax = perturbed_reconstructions.max()\n",
    "\n",
    "for i in range(5):\n",
    "    im = axs[i].imshow(perturbed_reconstructions[i, :, :, 0], cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    axs[i].set_title(f'Perturbation {perturbations[i]}')\n",
    "    axs[i].axis('off')\n",
    "    fig.colorbar(im, ax=axs[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"perturbations_feat1.pdf\", format=\"pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
