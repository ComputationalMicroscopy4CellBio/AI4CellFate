{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append(os.path.abspath(\"..\"))  #TODO: MAKE THE SRC PACKAGE WORK\n",
    "from src.training.new_optimised_train import train_autoencoder, train_cellfate\n",
    "from src.evaluation.evaluate import *\n",
    "from src.training.loss_functions import *\n",
    "from src.preprocessing.preprocessing_functions import *\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from src.models import Encoder, Decoder, Discriminator, mlp_classifier, complex_mlp_classifier\n",
    "from src.utils import *\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import tensorflow as tf\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (just after splitting)\n",
    "train_images = np.load(\"../data/images/train_images.npy\")\n",
    "test_images = np.load(\"../data/images/test_images.npy\")\n",
    "train_labels = np.load(\"../data/labels/train_labels.npy\")\n",
    "test_labels = np.load(\"../data/labels/test_labels.npy\")\n",
    "train_tracks = np.load(\"../data/tracks/train_tracks.npy\")\n",
    "test_tracks = np.load(\"../data/tracks/test_tracks.npy\")\n",
    "\n",
    "# Load full data\n",
    "\n",
    "x_train_full = np.load('../data/images/time_norm_train_images.npy')[:,0,:,:]\n",
    "#y_train_full = np.load('./data/labels/train_labels_augmented4.npy')\n",
    "#x_test = np.load('./data/images/time_norm_test_images.npy')[:,0,:,:]\n",
    "#y_test = np.load('./data/labels/test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "less_indexes = np.random.choice(np.arange(len(train_labels)), int(0.1 * len(train_labels)), replace=False)\n",
    "\n",
    "train_tracks[less_indexes][:,0,4:17].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = [1.0] # will probably have to try with different seeds #, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9\n",
    "\n",
    "# Will use frame 0\n",
    "\n",
    "#### FIGURE OUT WHY IT'S NOT WORKING FOR THE NEXT SIZE, AND WHY THE TABULAR DATA HAS AN ERROR\n",
    "def data_size_study(dataset_size, train_images, train_labels, train_tracks, test_images, test_labels, test_tracks, x_train_full, seed=42):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    confusion_matrices_cellfate = np.zeros((len(dataset_size), 2, 2))\n",
    "    confusion_matrices_tabular = np.zeros((len(dataset_size), 2, 2))\n",
    "\n",
    "    for size in dataset_size:\n",
    "        \n",
    "        # Create new output directory folder with the size \n",
    "\n",
    "        output_dir=f\"../results/data_labelling_study/split_{size}\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        less_indexes = np.random.choice(np.arange(len(train_labels)), int(size * len(train_labels)), replace=False)\n",
    "\n",
    "        # Get less training data\n",
    "        smaller_x_train_images = train_images[less_indexes]\n",
    "        smaller_y_train = train_labels[less_indexes]\n",
    "        smaller_x_train_tracks = train_tracks[less_indexes]\n",
    "\n",
    "        # Augment image data\n",
    "        smaller_train_images_augmented, smaller_train_labels_augmented = augment_dataset(smaller_x_train_images, smaller_y_train, augmentations)\n",
    "\n",
    "        # Stretch intensities of new images (train and test)\n",
    "        stretched_x_train_smaller, stretched_x_test = stretch_intensities_global(smaller_train_images_augmented, test_images)\n",
    "\n",
    "        # Pick only frame zero\n",
    "        x_train = stretched_x_train_smaller[:,0,:,:]\n",
    "        y_train = smaller_train_labels_augmented\n",
    "        x_test = stretched_x_test[:,0,:,:]\n",
    "        y_test = test_labels\n",
    "\n",
    "        print(\"X_train size: \", x_train.shape, \"Y_train size: \", y_train.shape, \"X_test size: \", x_test.shape, \"Y_test size: \", y_test.shape)\n",
    "\n",
    "        # IMAGES: Train autoencoder only\n",
    "        \n",
    "        config_ae = {\n",
    "            'batch_size': 30,\n",
    "            'epochs': 15,\n",
    "            'learning_rate': 0.001,\n",
    "            'seed': seed,\n",
    "            'latent_dim': 2,\n",
    "            'GaussianNoise_std': 0.003,\n",
    "            'lambda_recon': 5,\n",
    "            'lambda_adv': 1,\n",
    "        }\n",
    "\n",
    "        config_cellfate = {\n",
    "            'batch_size': 30,\n",
    "            'epochs': 100,\n",
    "            'learning_rate': 0.001,\n",
    "            'seed': seed,\n",
    "            'latent_dim': 2,\n",
    "            'GaussianNoise_std': 0.003,\n",
    "            'lambda_recon': 6,\n",
    "            'lambda_adv': 4,\n",
    "            'lambda_cov': 0.0001,\n",
    "            'lambda_contra': 8,\n",
    "        }\n",
    "\n",
    "        config_clf = {\n",
    "            'batch_size': 30,\n",
    "            'epochs': 50,\n",
    "            'learning_rate': 0.001,\n",
    "            'seed': seed,\n",
    "            'latent_dim': 2,\n",
    "        }\n",
    "\n",
    "        results_autoencoder = train_autoencoder(config_ae, x_train_full)\n",
    "        encoder = results_autoencoder['encoder']\n",
    "        decoder = results_autoencoder['decoder']\n",
    "        discriminator = results_autoencoder['discriminator']\n",
    "\n",
    "        # IMAGES: Train AIcellfate with smaller dataset\n",
    "\n",
    "        results_cellfate = train_cellfate(config_cellfate, encoder, decoder, discriminator, x_train, y_train, x_test, y_test) #lambda_recon=scaled_autoencoder_results['lambda_recon'], lambda_adv=scaled_autoencoder_results['lambda_adv']\n",
    "        encoder = results_cellfate['encoder']\n",
    "        decoder = results_cellfate['decoder']\n",
    "        discriminator = results_cellfate['discriminator']\n",
    "\n",
    "        save_model_weights_to_disk(encoder, decoder, discriminator, output_dir=output_dir)\n",
    "        \n",
    "        evaluator = Evaluation(output_dir)\n",
    "\n",
    "        # Evaluate the model (and saving everything)\n",
    "        z_imgs = encoder.predict(x_train)\n",
    "        recon_imgs = decoder.predict(z_imgs)\n",
    "        evaluator.reconstruction_images(x_train, recon_imgs[:,:,:,0], epoch=0)\n",
    "        evaluator.visualize_latent_space(z_imgs, y_train, epoch=0)\n",
    "        cov_matrix = cov_loss_terms(z_imgs)[0]\n",
    "        evaluator.plot_cov_matrix(cov_matrix, epoch=0) # the epoch is a placeholder, it doesnt mean anything (TODO: change these functions)\n",
    "\n",
    "        tf.keras.utils.set_random_seed(config_clf['seed'])\n",
    "\n",
    "        classifier = mlp_classifier(latent_dim=config_clf['latent_dim'])\n",
    "        classifier.compile(loss='sparse_categorical_crossentropy', optimizer= tf.keras.optimizers.Adam(learning_rate=config_clf['learning_rate']), metrics=['accuracy'])\n",
    "\n",
    "        x_val, x_test_, y_val, y_test_ = train_test_split(encoder.predict(x_test), y_test, test_size=0.5, random_state=42) \n",
    "        history = classifier.fit(encoder.predict(x_train), y_train, batch_size=config_clf['batch_size'], epochs=config_clf['epochs'], validation_data=(x_val, y_val)) \n",
    "\n",
    "        y_pred = classifier.predict(x_test_)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        num_classes = len(np.unique(y_test_))\n",
    "\n",
    "        # Calculate confusion matrix\n",
    "        cm = confusion_matrix(y_test_, y_pred_classes)\n",
    "\n",
    "        class_sums = cm.sum(axis=1, keepdims=True)\n",
    "        conf_matrix_normalized = cm / class_sums\n",
    "        \n",
    "        confusion_matrices_cellfate[dataset_size.index(size)] = conf_matrix_normalized\n",
    "\n",
    "        # Save confusion matrix\n",
    "        plot_confusion_matrix(y_test_, y_pred, num_classes)\n",
    "        np.save(f\"{output_dir}/confusion_matrices_cellfate.npy\", confusion_matrices_cellfate)\n",
    "\n",
    "        # TODO: add perturbations ?\n",
    "\n",
    "        # TRACKS: train classifier\n",
    "\n",
    "        config_tracks = {\n",
    "            'batch_size': 30,\n",
    "            'epochs': 50,\n",
    "            'learning_rate': 0.001,\n",
    "            'seed': 42,\n",
    "        }\n",
    "        \n",
    "        train_tracks_ = smaller_x_train_tracks[:,0,4:17]\n",
    "        test_tracks_ = test_tracks[:,0,4:17]\n",
    "        train_labels_ = smaller_y_train\n",
    "        test_labels_ = test_labels\n",
    "\n",
    "        print(\"Train tracks shape: \", train_tracks_.shape)\n",
    "\n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(train_labels_.flatten()), y=train_labels_.flatten())\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "        tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "        classifier = complex_mlp_classifier(latent_dim=train_tracks_.shape[1]) #[:, [3, 8]] \n",
    "        #classifier = simple_mlp_classifier(latent_dim=time_norm_train_track[:,frame,:].shape[1])\n",
    "\n",
    "        # Train the classifier\n",
    "        classifier.compile(loss='sparse_categorical_crossentropy', optimizer= tf.keras.optimizers.Adam(learning_rate=config_tracks['learning_rate']), metrics=['accuracy'])\n",
    "        classifier.summary()\n",
    "\n",
    "        x_val_tracks, x_test_tracks, y_val_tracks, y_test_tracks = train_test_split(test_tracks_, test_labels_, test_size=0.5, random_state=42) # 42 random state\n",
    "\n",
    "        history = classifier.fit(train_tracks_, train_labels_, batch_size=config_tracks['batch_size'], epochs=config_tracks['epochs'], validation_data=(x_val_tracks, y_val_tracks), class_weight=class_weights) \n",
    "\n",
    "        y_pred = classifier.predict(x_test_tracks)\n",
    "\n",
    "        num_classes = len(np.unique(train_labels_))\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # Calculate confusion matrix\n",
    "        cm = confusion_matrix(y_test_tracks, y_pred_classes)\n",
    "\n",
    "        class_sums = cm.sum(axis=1, keepdims=True)\n",
    "        conf_matrix_normalized = cm / class_sums\n",
    "\n",
    "        print(conf_matrix_normalized)\n",
    "\n",
    "        confusion_matrices_tabular[dataset_size.index(size)] = conf_matrix_normalized\n",
    "        np.save(f\"{output_dir}/confusion_matrices_tabular.npy\", confusion_matrices_tabular)\n",
    "\n",
    "    return confusion_matrices_cellfate, confusion_matrices_tabular\n",
    "\n",
    "\n",
    "#np.save(\"../results/data_labelling_study/smaller_x_train_images.npy\", smaller_x_train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size:  (2184, 20, 20) Y_train size:  (2184,) X_test size:  (277, 20, 20) Y_test size:  (277,)\n",
      "Training with batch size: 30, epochs: 15, learning rate: 0.001, seed: 42, latent dim: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inescunha/anaconda3/envs/interpret/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/inescunha/anaconda3/envs/interpret/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: Reconstruction loss: 1.2867, Adversarial loss: 0.7489, lambda recon: 5.0000, lambda adv: 1.0000\n",
      "Epoch 2/15: Reconstruction loss: 0.7749, Adversarial loss: 0.7269, lambda recon: 5.0000, lambda adv: 1.0000\n",
      "Epoch 3/15: Reconstruction loss: 0.7638, Adversarial loss: 0.7135, lambda recon: 5.0000, lambda adv: 1.0000\n",
      "Epoch 4/15: Reconstruction loss: 0.7467, Adversarial loss: 0.7116, lambda recon: 5.0000, lambda adv: 1.0000\n",
      "Epoch 5/15: Reconstruction loss: 0.7450, Adversarial loss: 0.7094, lambda recon: 5.0000, lambda adv: 1.0000\n",
      "Epoch 6/15: Reconstruction loss: 0.7531, Adversarial loss: 0.6986, lambda recon: 5.0000, lambda adv: 1.0000\n",
      "Epoch 7/15: Reconstruction loss: 0.7237, Adversarial loss: 0.7067, lambda recon: 5.0000, lambda adv: 1.0000\n",
      "Epoch 8/15: Reconstruction loss: 0.7281, Adversarial loss: 0.7037, lambda recon: 5.0000, lambda adv: 1.0000\n",
      "Epoch 9/15: Reconstruction loss: 0.7274, Adversarial loss: 0.6983, lambda recon: 5.0000, lambda adv: 1.0000\n",
      "Epoch 10/15: Reconstruction loss: 0.7240, Adversarial loss: 0.7008, lambda recon: 5.0000, lambda adv: 1.0000\n",
      "Epoch 11/15: Reconstruction loss: 0.7207, Adversarial loss: 0.7006, lambda recon: 5.0000, lambda adv: 1.0000\n",
      "Epoch 12/15: Reconstruction loss: 0.7297, Adversarial loss: 0.6933, lambda recon: 5.0000, lambda adv: 1.0000\n",
      "Epoch 13/15: Reconstruction loss: 0.7210, Adversarial loss: 0.6991, lambda recon: 5.0000, lambda adv: 1.0000\n",
      "Epoch 14/15: Reconstruction loss: 0.7129, Adversarial loss: 0.6996, lambda recon: 5.0000, lambda adv: 1.0000\n",
      "Epoch 15/15: Reconstruction loss: 0.7313, Adversarial loss: 0.6959, lambda recon: 5.0000, lambda adv: 1.0000\n",
      "Training with batch size: 30, epochs: 100, learning rate: 0.001, seed: 42, latent dim: 2\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "kl_divergence[0]: 0.05946908362506794 kl_divergence[1]: 0.09075904743292505\n",
      "Latent Space is Gaussian-distributed!\n",
      "Eucledian distance: 0.5845544934272766\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (24.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6\u001b[0m (24.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (24.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6\u001b[0m (24.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6040 - loss: 0.6838 - val_accuracy: 0.6449 - val_loss: 0.6113\n",
      "Epoch 2/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - accuracy: 0.6021 - loss: 0.6756 - val_accuracy: 0.6377 - val_loss: 0.6251\n",
      "Epoch 3/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.6007 - loss: 0.6698 - val_accuracy: 0.6377 - val_loss: 0.6325\n",
      "Epoch 4/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.6056 - loss: 0.6470 - val_accuracy: 0.6304 - val_loss: 0.6394\n",
      "Epoch 5/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.6120 - loss: 0.6475 - val_accuracy: 0.6159 - val_loss: 0.6449\n",
      "Epoch 6/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.5810 - loss: 0.6556 - val_accuracy: 0.6159 - val_loss: 0.6461\n",
      "Epoch 7/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.6026 - loss: 0.6551 - val_accuracy: 0.6304 - val_loss: 0.6456\n",
      "Epoch 8/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.6014 - loss: 0.6598 - val_accuracy: 0.6232 - val_loss: 0.6492\n",
      "Epoch 9/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.5986 - loss: 0.6547 - val_accuracy: 0.6159 - val_loss: 0.6500\n",
      "Epoch 10/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.6094 - loss: 0.6524 - val_accuracy: 0.6087 - val_loss: 0.6508\n",
      "Epoch 11/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.6051 - loss: 0.6492 - val_accuracy: 0.6087 - val_loss: 0.6520\n",
      "Epoch 12/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.6010 - loss: 0.6551 - val_accuracy: 0.6087 - val_loss: 0.6503\n",
      "Epoch 13/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.5947 - loss: 0.6492 - val_accuracy: 0.6232 - val_loss: 0.6493\n",
      "Epoch 14/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.6244 - loss: 0.6487 - val_accuracy: 0.6304 - val_loss: 0.6495\n",
      "Epoch 15/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.5971 - loss: 0.6613 - val_accuracy: 0.6159 - val_loss: 0.6510\n",
      "Epoch 16/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.6117 - loss: 0.6487 - val_accuracy: 0.6087 - val_loss: 0.6517\n",
      "Epoch 17/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.6040 - loss: 0.6541 - val_accuracy: 0.6087 - val_loss: 0.6545\n",
      "Epoch 18/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.6269 - loss: 0.6475 - val_accuracy: 0.6159 - val_loss: 0.6527\n",
      "Epoch 19/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.6147 - loss: 0.6543 - val_accuracy: 0.6304 - val_loss: 0.6483\n",
      "Epoch 20/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.6067 - loss: 0.6519 - val_accuracy: 0.6304 - val_loss: 0.6455\n",
      "Epoch 21/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.5971 - loss: 0.6546 - val_accuracy: 0.6304 - val_loss: 0.6474\n",
      "Epoch 22/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.6114 - loss: 0.6488 - val_accuracy: 0.6159 - val_loss: 0.6508\n",
      "Epoch 23/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.6109 - loss: 0.6533 - val_accuracy: 0.6159 - val_loss: 0.6541\n",
      "Epoch 24/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.5959 - loss: 0.6497 - val_accuracy: 0.6159 - val_loss: 0.6511\n",
      "Epoch 25/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.6185 - loss: 0.6514 - val_accuracy: 0.6304 - val_loss: 0.6477\n",
      "Epoch 26/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.6171 - loss: 0.6494 - val_accuracy: 0.6304 - val_loss: 0.6473\n",
      "Epoch 27/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.6144 - loss: 0.6459 - val_accuracy: 0.6304 - val_loss: 0.6479\n",
      "Epoch 28/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.6009 - loss: 0.6594 - val_accuracy: 0.6304 - val_loss: 0.6487\n",
      "Epoch 29/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.6154 - loss: 0.6509 - val_accuracy: 0.6304 - val_loss: 0.6488\n",
      "Epoch 30/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.6182 - loss: 0.6416 - val_accuracy: 0.6159 - val_loss: 0.6503\n",
      "Epoch 31/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.6127 - loss: 0.6540 - val_accuracy: 0.6159 - val_loss: 0.6504\n",
      "Epoch 32/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.6036 - loss: 0.6516 - val_accuracy: 0.6159 - val_loss: 0.6510\n",
      "Epoch 33/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.5907 - loss: 0.6535 - val_accuracy: 0.6159 - val_loss: 0.6522\n",
      "Epoch 34/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.6153 - loss: 0.6478 - val_accuracy: 0.6232 - val_loss: 0.6520\n",
      "Epoch 35/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.6088 - loss: 0.6534 - val_accuracy: 0.6159 - val_loss: 0.6488\n",
      "Epoch 36/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.6255 - loss: 0.6519 - val_accuracy: 0.6159 - val_loss: 0.6521\n",
      "Epoch 37/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.5828 - loss: 0.6617 - val_accuracy: 0.6087 - val_loss: 0.6527\n",
      "Epoch 38/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.5856 - loss: 0.6553 - val_accuracy: 0.6159 - val_loss: 0.6506\n",
      "Epoch 39/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.6018 - loss: 0.6510 - val_accuracy: 0.5942 - val_loss: 0.6546\n",
      "Epoch 40/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.5943 - loss: 0.6559 - val_accuracy: 0.6159 - val_loss: 0.6488\n",
      "Epoch 41/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.5973 - loss: 0.6574 - val_accuracy: 0.6159 - val_loss: 0.6498\n",
      "Epoch 42/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.6102 - loss: 0.6507 - val_accuracy: 0.6304 - val_loss: 0.6480\n",
      "Epoch 43/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.5861 - loss: 0.6594 - val_accuracy: 0.6304 - val_loss: 0.6491\n",
      "Epoch 44/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.6226 - loss: 0.6467 - val_accuracy: 0.6304 - val_loss: 0.6462\n",
      "Epoch 45/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.5973 - loss: 0.6544 - val_accuracy: 0.6304 - val_loss: 0.6482\n",
      "Epoch 46/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.6227 - loss: 0.6494 - val_accuracy: 0.6304 - val_loss: 0.6455\n",
      "Epoch 47/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.5976 - loss: 0.6497 - val_accuracy: 0.6304 - val_loss: 0.6475\n",
      "Epoch 48/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.6049 - loss: 0.6570 - val_accuracy: 0.6087 - val_loss: 0.6515\n",
      "Epoch 49/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.6071 - loss: 0.6502 - val_accuracy: 0.6159 - val_loss: 0.6520\n",
      "Epoch 50/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.5915 - loss: 0.6553 - val_accuracy: 0.6232 - val_loss: 0.6503\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Mean diagonal: 0.5919, Precision: 0.5948\n",
      "Epoch 1/100: Reconstruction loss: 0.9351, Adversarial loss: 2.8105, Contrastive loss: 5.4152, Covariance loss: 0.0000, lamdba recon: 6.0000, lambda adv: 4.0000, lambda cov: 0.0001, lambda contra: 8.0000\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "kl_divergence[0]: 0.6129502240232703 kl_divergence[1]: 0.24184403939966898\n",
      "Epoch 2/100: Reconstruction loss: 1.0629, Adversarial loss: 2.8056, Contrastive loss: 5.1765, Covariance loss: 0.0000, lamdba recon: 6.0000, lambda adv: 4.0000, lambda cov: 0.0001, lambda contra: 8.0000\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "kl_divergence[0]: 0.5376459211753652 kl_divergence[1]: 0.04686354340913259\n",
      "Epoch 3/100: Reconstruction loss: 1.0272, Adversarial loss: 2.8382, Contrastive loss: 5.1455, Covariance loss: 0.0000, lamdba recon: 6.0000, lambda adv: 4.0000, lambda cov: 0.0001, lambda contra: 8.0000\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "kl_divergence[0]: 0.6388237047609503 kl_divergence[1]: 0.14891832629102394\n",
      "Epoch 4/100: Reconstruction loss: 1.0192, Adversarial loss: 2.8267, Contrastive loss: 5.1970, Covariance loss: 0.0000, lamdba recon: 6.0000, lambda adv: 4.0000, lambda cov: 0.0001, lambda contra: 8.0000\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "kl_divergence[0]: 0.46079863524035686 kl_divergence[1]: 0.27408146832352714\n",
      "Epoch 5/100: Reconstruction loss: 1.0687, Adversarial loss: 2.8244, Contrastive loss: 5.0337, Covariance loss: 0.0001, lamdba recon: 6.0000, lambda adv: 4.0000, lambda cov: 0.0001, lambda contra: 8.0000\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "kl_divergence[0]: 0.2762379805829119 kl_divergence[1]: 0.15366427568786645\n",
      "Epoch 6/100: Reconstruction loss: 1.0735, Adversarial loss: 2.8132, Contrastive loss: 5.0240, Covariance loss: 0.0001, lamdba recon: 6.0000, lambda adv: 4.0000, lambda cov: 0.0001, lambda contra: 8.0000\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "kl_divergence[0]: 0.09102683517243795 kl_divergence[1]: 0.2264981920230412\n",
      "Epoch 7/100: Reconstruction loss: 1.0264, Adversarial loss: 2.8175, Contrastive loss: 5.1094, Covariance loss: 0.0001, lamdba recon: 6.0000, lambda adv: 4.0000, lambda cov: 0.0001, lambda contra: 8.0000\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "kl_divergence[0]: 0.5563982091637775 kl_divergence[1]: 0.20499975413143504\n",
      "Epoch 8/100: Reconstruction loss: 1.0275, Adversarial loss: 2.8382, Contrastive loss: 5.0806, Covariance loss: 0.0000, lamdba recon: 6.0000, lambda adv: 4.0000, lambda cov: 0.0001, lambda contra: 8.0000\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "kl_divergence[0]: 0.061734987309144736 kl_divergence[1]: 1.6773170819933396\n",
      "Epoch 9/100: Reconstruction loss: 1.0367, Adversarial loss: 2.8268, Contrastive loss: 4.9226, Covariance loss: 0.0000, lamdba recon: 6.0000, lambda adv: 4.0000, lambda cov: 0.0001, lambda contra: 8.0000\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "kl_divergence[0]: 0.027252535414815045 kl_divergence[1]: 0.12028958597301993\n",
      "Latent Space is Gaussian-distributed!\n",
      "Eucledian distance: 0.9421858787536621\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (24.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6\u001b[0m (24.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (24.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6\u001b[0m (24.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6769 - loss: 0.6039 - val_accuracy: 0.6884 - val_loss: 0.6085\n",
      "Epoch 2/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.6665 - loss: 0.6049 - val_accuracy: 0.6812 - val_loss: 0.6094\n",
      "Epoch 3/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.6692 - loss: 0.6049 - val_accuracy: 0.6812 - val_loss: 0.6072\n",
      "Epoch 4/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.6714 - loss: 0.5989 - val_accuracy: 0.6667 - val_loss: 0.6076\n",
      "Epoch 5/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.6713 - loss: 0.5983 - val_accuracy: 0.6667 - val_loss: 0.6071\n",
      "Epoch 6/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.6735 - loss: 0.5950 - val_accuracy: 0.6594 - val_loss: 0.6086\n",
      "Epoch 7/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6668 - loss: 0.6007 - val_accuracy: 0.6594 - val_loss: 0.6089\n",
      "Epoch 8/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.6681 - loss: 0.6058 - val_accuracy: 0.6594 - val_loss: 0.6091\n",
      "Epoch 9/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.6839 - loss: 0.5905 - val_accuracy: 0.6667 - val_loss: 0.6074\n",
      "Epoch 10/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.6861 - loss: 0.5941 - val_accuracy: 0.6594 - val_loss: 0.6093\n",
      "Epoch 11/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.6846 - loss: 0.5823 - val_accuracy: 0.6667 - val_loss: 0.6084\n",
      "Epoch 12/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.6724 - loss: 0.6000 - val_accuracy: 0.6594 - val_loss: 0.6102\n",
      "Epoch 13/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.6838 - loss: 0.5865 - val_accuracy: 0.6594 - val_loss: 0.6103\n",
      "Epoch 14/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.6578 - loss: 0.6041 - val_accuracy: 0.6594 - val_loss: 0.6101\n",
      "Epoch 15/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.6684 - loss: 0.5887 - val_accuracy: 0.6594 - val_loss: 0.6102\n",
      "Epoch 16/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.6630 - loss: 0.6011 - val_accuracy: 0.6594 - val_loss: 0.6097\n",
      "Epoch 17/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.6937 - loss: 0.5884 - val_accuracy: 0.6594 - val_loss: 0.6090\n",
      "Epoch 18/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.6766 - loss: 0.6045 - val_accuracy: 0.6667 - val_loss: 0.6078\n",
      "Epoch 19/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.6701 - loss: 0.6036 - val_accuracy: 0.6667 - val_loss: 0.6086\n",
      "Epoch 20/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.6865 - loss: 0.5912 - val_accuracy: 0.6667 - val_loss: 0.6076\n",
      "Epoch 21/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.6875 - loss: 0.5868 - val_accuracy: 0.6594 - val_loss: 0.6087\n",
      "Epoch 22/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.6999 - loss: 0.5831 - val_accuracy: 0.6739 - val_loss: 0.6067\n",
      "Epoch 23/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.6906 - loss: 0.5885 - val_accuracy: 0.6739 - val_loss: 0.6060\n",
      "Epoch 24/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.6725 - loss: 0.5987 - val_accuracy: 0.6739 - val_loss: 0.6071\n",
      "Epoch 25/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.6855 - loss: 0.5939 - val_accuracy: 0.6594 - val_loss: 0.6100\n",
      "Epoch 26/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.6847 - loss: 0.5785 - val_accuracy: 0.6594 - val_loss: 0.6098\n",
      "Epoch 27/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - accuracy: 0.6873 - loss: 0.5930 - val_accuracy: 0.6594 - val_loss: 0.6102\n",
      "Epoch 28/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.6759 - loss: 0.5998 - val_accuracy: 0.6667 - val_loss: 0.6087\n",
      "Epoch 29/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.6873 - loss: 0.5931 - val_accuracy: 0.6594 - val_loss: 0.6069\n",
      "Epoch 30/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.6907 - loss: 0.5899 - val_accuracy: 0.6594 - val_loss: 0.6087\n",
      "Epoch 31/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.6811 - loss: 0.5999 - val_accuracy: 0.6594 - val_loss: 0.6097\n",
      "Epoch 32/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.6787 - loss: 0.5999 - val_accuracy: 0.6594 - val_loss: 0.6091\n",
      "Epoch 33/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.6847 - loss: 0.5933 - val_accuracy: 0.6594 - val_loss: 0.6106\n",
      "Epoch 34/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.6853 - loss: 0.5926 - val_accuracy: 0.6522 - val_loss: 0.6107\n",
      "Epoch 35/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.6836 - loss: 0.5918 - val_accuracy: 0.6522 - val_loss: 0.6105\n",
      "Epoch 36/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.6874 - loss: 0.5908 - val_accuracy: 0.6594 - val_loss: 0.6094\n",
      "Epoch 37/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.6906 - loss: 0.5914 - val_accuracy: 0.6739 - val_loss: 0.6072\n",
      "Epoch 38/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.6751 - loss: 0.5951 - val_accuracy: 0.6667 - val_loss: 0.6071\n",
      "Epoch 39/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.6828 - loss: 0.5869 - val_accuracy: 0.6667 - val_loss: 0.6084\n",
      "Epoch 40/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.6803 - loss: 0.5891 - val_accuracy: 0.6667 - val_loss: 0.6089\n",
      "Epoch 41/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.6795 - loss: 0.5957 - val_accuracy: 0.6594 - val_loss: 0.6092\n",
      "Epoch 42/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.6896 - loss: 0.5919 - val_accuracy: 0.6522 - val_loss: 0.6109\n",
      "Epoch 43/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.6719 - loss: 0.5922 - val_accuracy: 0.6594 - val_loss: 0.6108\n",
      "Epoch 44/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.6858 - loss: 0.5914 - val_accuracy: 0.6594 - val_loss: 0.6102\n",
      "Epoch 45/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.6805 - loss: 0.5992 - val_accuracy: 0.6594 - val_loss: 0.6104\n",
      "Epoch 46/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.6762 - loss: 0.5981 - val_accuracy: 0.6667 - val_loss: 0.6077\n",
      "Epoch 47/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.6656 - loss: 0.6017 - val_accuracy: 0.6594 - val_loss: 0.6081\n",
      "Epoch 48/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.6739 - loss: 0.5954 - val_accuracy: 0.6594 - val_loss: 0.6090\n",
      "Epoch 49/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.6905 - loss: 0.5910 - val_accuracy: 0.6594 - val_loss: 0.6085\n",
      "Epoch 50/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.6965 - loss: 0.5877 - val_accuracy: 0.6594 - val_loss: 0.6094\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Mean diagonal: 0.6501, Precision: 0.6592\n",
      "Epoch 10/100: Reconstruction loss: 1.0430, Adversarial loss: 2.8202, Contrastive loss: 4.8907, Covariance loss: 0.0000, lamdba recon: 6.0000, lambda adv: 4.0000, lambda cov: 0.0001, lambda contra: 8.0000\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "kl_divergence[0]: 0.06122981545034878 kl_divergence[1]: 0.28599595602609706\n",
      "Epoch 11/100: Reconstruction loss: 1.0621, Adversarial loss: 2.8420, Contrastive loss: 5.0229, Covariance loss: 0.0000, lamdba recon: 6.0000, lambda adv: 4.0000, lambda cov: 0.0001, lambda contra: 8.0000\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "kl_divergence[0]: 0.2056520197775387 kl_divergence[1]: 0.3811514055391764\n",
      "Epoch 12/100: Reconstruction loss: 1.0503, Adversarial loss: 2.8252, Contrastive loss: 4.8643, Covariance loss: 0.0000, lamdba recon: 6.0000, lambda adv: 4.0000, lambda cov: 0.0001, lambda contra: 8.0000\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "kl_divergence[0]: 0.3407571341122715 kl_divergence[1]: 0.09522154270262721\n",
      "Epoch 13/100: Reconstruction loss: 1.0197, Adversarial loss: 2.8461, Contrastive loss: 4.9712, Covariance loss: 0.0000, lamdba recon: 6.0000, lambda adv: 4.0000, lambda cov: 0.0001, lambda contra: 8.0000\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "kl_divergence[0]: 0.11332937192657727 kl_divergence[1]: 0.08680058958363487\n",
      "Latent Space is Gaussian-distributed!\n",
      "Eucledian distance: 1.1061662435531616\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (24.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6\u001b[0m (24.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (24.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6\u001b[0m (24.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6236 - loss: 0.6960 - val_accuracy: 0.7029 - val_loss: 0.5838\n",
      "Epoch 2/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.6474 - loss: 0.6500 - val_accuracy: 0.6957 - val_loss: 0.5925\n",
      "Epoch 3/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.6499 - loss: 0.6287 - val_accuracy: 0.6884 - val_loss: 0.6012\n",
      "Epoch 4/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.6329 - loss: 0.6391 - val_accuracy: 0.6812 - val_loss: 0.6073\n",
      "Epoch 5/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.6575 - loss: 0.6060 - val_accuracy: 0.6594 - val_loss: 0.6132\n",
      "Epoch 6/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.6587 - loss: 0.6058 - val_accuracy: 0.6522 - val_loss: 0.6190\n",
      "Epoch 7/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.6405 - loss: 0.6250 - val_accuracy: 0.6449 - val_loss: 0.6232\n",
      "Epoch 8/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.6317 - loss: 0.6160 - val_accuracy: 0.6449 - val_loss: 0.6273\n",
      "Epoch 9/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.6664 - loss: 0.5950 - val_accuracy: 0.6377 - val_loss: 0.6298\n",
      "Epoch 10/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.6678 - loss: 0.5890 - val_accuracy: 0.6377 - val_loss: 0.6331\n",
      "Epoch 11/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.6363 - loss: 0.6107 - val_accuracy: 0.6232 - val_loss: 0.6367\n",
      "Epoch 12/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.6451 - loss: 0.6061 - val_accuracy: 0.6159 - val_loss: 0.6367\n",
      "Epoch 13/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.6698 - loss: 0.6004 - val_accuracy: 0.6159 - val_loss: 0.6371\n",
      "Epoch 14/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.6643 - loss: 0.5991 - val_accuracy: 0.6159 - val_loss: 0.6382\n",
      "Epoch 15/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.6590 - loss: 0.6050 - val_accuracy: 0.6159 - val_loss: 0.6372\n",
      "Epoch 16/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.6483 - loss: 0.5939 - val_accuracy: 0.6304 - val_loss: 0.6348\n",
      "Epoch 17/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.6571 - loss: 0.5960 - val_accuracy: 0.6304 - val_loss: 0.6331\n",
      "Epoch 18/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.6611 - loss: 0.6030 - val_accuracy: 0.6232 - val_loss: 0.6344\n",
      "Epoch 19/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.6450 - loss: 0.6081 - val_accuracy: 0.6232 - val_loss: 0.6353\n",
      "Epoch 20/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.6586 - loss: 0.6025 - val_accuracy: 0.6304 - val_loss: 0.6329\n",
      "Epoch 21/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.6432 - loss: 0.6078 - val_accuracy: 0.6304 - val_loss: 0.6300\n",
      "Epoch 22/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.6417 - loss: 0.6153 - val_accuracy: 0.6377 - val_loss: 0.6288\n",
      "Epoch 23/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.6445 - loss: 0.6114 - val_accuracy: 0.6304 - val_loss: 0.6286\n",
      "Epoch 24/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.6403 - loss: 0.6126 - val_accuracy: 0.6304 - val_loss: 0.6296\n",
      "Epoch 25/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.6586 - loss: 0.6061 - val_accuracy: 0.6377 - val_loss: 0.6292\n",
      "Epoch 26/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.6443 - loss: 0.6113 - val_accuracy: 0.6377 - val_loss: 0.6292\n",
      "Epoch 27/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.6558 - loss: 0.5993 - val_accuracy: 0.6304 - val_loss: 0.6290\n",
      "Epoch 28/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.6529 - loss: 0.5996 - val_accuracy: 0.6304 - val_loss: 0.6289\n",
      "Epoch 29/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.6547 - loss: 0.6125 - val_accuracy: 0.6232 - val_loss: 0.6304\n",
      "Epoch 30/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.6504 - loss: 0.6009 - val_accuracy: 0.6304 - val_loss: 0.6289\n",
      "Epoch 31/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.6689 - loss: 0.5859 - val_accuracy: 0.6304 - val_loss: 0.6306\n",
      "Epoch 32/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.6464 - loss: 0.6049 - val_accuracy: 0.6304 - val_loss: 0.6320\n",
      "Epoch 33/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.6281 - loss: 0.6201 - val_accuracy: 0.6304 - val_loss: 0.6319\n",
      "Epoch 34/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.6421 - loss: 0.6056 - val_accuracy: 0.6377 - val_loss: 0.6308\n",
      "Epoch 35/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.6635 - loss: 0.5956 - val_accuracy: 0.6304 - val_loss: 0.6307\n",
      "Epoch 36/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.6581 - loss: 0.6068 - val_accuracy: 0.6377 - val_loss: 0.6289\n",
      "Epoch 37/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.6645 - loss: 0.5966 - val_accuracy: 0.6377 - val_loss: 0.6297\n",
      "Epoch 38/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.6471 - loss: 0.6000 - val_accuracy: 0.6377 - val_loss: 0.6303\n",
      "Epoch 39/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.6635 - loss: 0.5921 - val_accuracy: 0.6304 - val_loss: 0.6298\n",
      "Epoch 40/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.6585 - loss: 0.6082 - val_accuracy: 0.6304 - val_loss: 0.6304\n",
      "Epoch 41/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - accuracy: 0.6532 - loss: 0.6006 - val_accuracy: 0.6304 - val_loss: 0.6295\n",
      "Epoch 42/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.6381 - loss: 0.6053 - val_accuracy: 0.6304 - val_loss: 0.6302\n",
      "Epoch 43/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.6607 - loss: 0.5990 - val_accuracy: 0.6304 - val_loss: 0.6281\n",
      "Epoch 44/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.6444 - loss: 0.6034 - val_accuracy: 0.6304 - val_loss: 0.6289\n",
      "Epoch 45/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.6438 - loss: 0.6140 - val_accuracy: 0.6304 - val_loss: 0.6283\n",
      "Epoch 46/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.6502 - loss: 0.6108 - val_accuracy: 0.6377 - val_loss: 0.6275\n",
      "Epoch 47/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.6509 - loss: 0.6034 - val_accuracy: 0.6304 - val_loss: 0.6267\n",
      "Epoch 48/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.6617 - loss: 0.6032 - val_accuracy: 0.6304 - val_loss: 0.6291\n",
      "Epoch 49/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.6478 - loss: 0.6162 - val_accuracy: 0.6304 - val_loss: 0.6291\n",
      "Epoch 50/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.6523 - loss: 0.6030 - val_accuracy: 0.6377 - val_loss: 0.6293\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Mean diagonal: 0.6279, Precision: 0.6228\n",
      "Epoch 14/100: Reconstruction loss: 1.0369, Adversarial loss: 2.8017, Contrastive loss: 4.8098, Covariance loss: 0.0000, lamdba recon: 6.0000, lambda adv: 4.0000, lambda cov: 0.0001, lambda contra: 8.0000\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "kl_divergence[0]: 0.2116694493550951 kl_divergence[1]: 0.19235804623257297\n",
      "Epoch 15/100: Reconstruction loss: 1.0334, Adversarial loss: 2.8341, Contrastive loss: 4.8893, Covariance loss: 0.0000, lamdba recon: 6.0000, lambda adv: 4.0000, lambda cov: 0.0001, lambda contra: 8.0000\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "kl_divergence[0]: 0.0366895190288554 kl_divergence[1]: 0.1799085312650124\n",
      "Latent Space is Gaussian-distributed!\n",
      "Eucledian distance: 1.0184136629104614\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (24.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6\u001b[0m (24.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (24.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6\u001b[0m (24.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5745 - loss: 0.6940 - val_accuracy: 0.6522 - val_loss: 0.6636\n",
      "Epoch 2/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.6428 - loss: 0.6524 - val_accuracy: 0.6159 - val_loss: 0.6557\n",
      "Epoch 3/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.6392 - loss: 0.6388 - val_accuracy: 0.6304 - val_loss: 0.6481\n",
      "Epoch 4/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.6438 - loss: 0.6265 - val_accuracy: 0.6232 - val_loss: 0.6427\n",
      "Epoch 5/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.6533 - loss: 0.6170 - val_accuracy: 0.6304 - val_loss: 0.6384\n",
      "Epoch 6/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.6545 - loss: 0.6159 - val_accuracy: 0.6232 - val_loss: 0.6357\n",
      "Epoch 7/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.6655 - loss: 0.6133 - val_accuracy: 0.6304 - val_loss: 0.6327\n",
      "Epoch 8/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.6552 - loss: 0.6130 - val_accuracy: 0.6232 - val_loss: 0.6313\n",
      "Epoch 9/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.6559 - loss: 0.6140 - val_accuracy: 0.6304 - val_loss: 0.6309\n",
      "Epoch 10/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.6594 - loss: 0.6099 - val_accuracy: 0.6377 - val_loss: 0.6298\n",
      "Epoch 11/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.6498 - loss: 0.6120 - val_accuracy: 0.6304 - val_loss: 0.6310\n",
      "Epoch 12/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.6703 - loss: 0.6078 - val_accuracy: 0.6304 - val_loss: 0.6298\n",
      "Epoch 13/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.6571 - loss: 0.6126 - val_accuracy: 0.6304 - val_loss: 0.6306\n",
      "Epoch 14/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - accuracy: 0.6569 - loss: 0.6081 - val_accuracy: 0.6304 - val_loss: 0.6311\n",
      "Epoch 15/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.6659 - loss: 0.6032 - val_accuracy: 0.6304 - val_loss: 0.6302\n",
      "Epoch 16/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.6623 - loss: 0.5991 - val_accuracy: 0.6304 - val_loss: 0.6303\n",
      "Epoch 17/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.6541 - loss: 0.6141 - val_accuracy: 0.6377 - val_loss: 0.6275\n",
      "Epoch 18/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.6545 - loss: 0.6095 - val_accuracy: 0.6377 - val_loss: 0.6270\n",
      "Epoch 19/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.6646 - loss: 0.6024 - val_accuracy: 0.6377 - val_loss: 0.6276\n",
      "Epoch 20/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.6499 - loss: 0.6076 - val_accuracy: 0.6377 - val_loss: 0.6287\n",
      "Epoch 21/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.6528 - loss: 0.6103 - val_accuracy: 0.6377 - val_loss: 0.6311\n",
      "Epoch 22/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.6645 - loss: 0.6088 - val_accuracy: 0.6304 - val_loss: 0.6324\n",
      "Epoch 23/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.6514 - loss: 0.6107 - val_accuracy: 0.6304 - val_loss: 0.6315\n",
      "Epoch 24/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.6762 - loss: 0.5982 - val_accuracy: 0.6377 - val_loss: 0.6311\n",
      "Epoch 25/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.6523 - loss: 0.6118 - val_accuracy: 0.6304 - val_loss: 0.6308\n",
      "Epoch 26/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.6482 - loss: 0.6089 - val_accuracy: 0.6304 - val_loss: 0.6315\n",
      "Epoch 27/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.6676 - loss: 0.6132 - val_accuracy: 0.6304 - val_loss: 0.6303\n",
      "Epoch 28/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.6386 - loss: 0.6149 - val_accuracy: 0.6377 - val_loss: 0.6303\n",
      "Epoch 29/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.6821 - loss: 0.6003 - val_accuracy: 0.6232 - val_loss: 0.6347\n",
      "Epoch 30/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.6644 - loss: 0.6102 - val_accuracy: 0.6232 - val_loss: 0.6343\n",
      "Epoch 31/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.6696 - loss: 0.5959 - val_accuracy: 0.6304 - val_loss: 0.6314\n",
      "Epoch 32/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.6471 - loss: 0.6125 - val_accuracy: 0.6377 - val_loss: 0.6317\n",
      "Epoch 33/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.6657 - loss: 0.6051 - val_accuracy: 0.6304 - val_loss: 0.6331\n",
      "Epoch 34/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.6447 - loss: 0.6185 - val_accuracy: 0.6304 - val_loss: 0.6322\n",
      "Epoch 35/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.6463 - loss: 0.6165 - val_accuracy: 0.6304 - val_loss: 0.6314\n",
      "Epoch 36/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.6690 - loss: 0.6055 - val_accuracy: 0.6377 - val_loss: 0.6322\n",
      "Epoch 37/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.6590 - loss: 0.6156 - val_accuracy: 0.6304 - val_loss: 0.6328\n",
      "Epoch 38/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.6371 - loss: 0.6132 - val_accuracy: 0.6377 - val_loss: 0.6324\n",
      "Epoch 39/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.6681 - loss: 0.5941 - val_accuracy: 0.6304 - val_loss: 0.6310\n",
      "Epoch 40/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.6620 - loss: 0.6097 - val_accuracy: 0.6304 - val_loss: 0.6325\n",
      "Epoch 41/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.6586 - loss: 0.6111 - val_accuracy: 0.6304 - val_loss: 0.6331\n",
      "Epoch 42/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.6642 - loss: 0.6116 - val_accuracy: 0.6377 - val_loss: 0.6310\n",
      "Epoch 43/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.6728 - loss: 0.5996 - val_accuracy: 0.6377 - val_loss: 0.6308\n",
      "Epoch 44/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.6542 - loss: 0.6066 - val_accuracy: 0.6304 - val_loss: 0.6328\n",
      "Epoch 45/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.6453 - loss: 0.6250 - val_accuracy: 0.6377 - val_loss: 0.6306\n",
      "Epoch 46/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.6619 - loss: 0.6148 - val_accuracy: 0.6377 - val_loss: 0.6303\n",
      "Epoch 47/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.6530 - loss: 0.6211 - val_accuracy: 0.6304 - val_loss: 0.6321\n",
      "Epoch 48/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.6623 - loss: 0.6020 - val_accuracy: 0.6377 - val_loss: 0.6296\n",
      "Epoch 49/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.6523 - loss: 0.6126 - val_accuracy: 0.6449 - val_loss: 0.6279\n",
      "Epoch 50/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.6567 - loss: 0.6117 - val_accuracy: 0.6377 - val_loss: 0.6292\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Mean diagonal: 0.6100, Precision: 0.6022\n",
      "Epoch 16/100: Reconstruction loss: 1.0293, Adversarial loss: 2.8498, Contrastive loss: 4.9721, Covariance loss: 0.0000, lamdba recon: 6.0000, lambda adv: 4.0000, lambda cov: 0.0001, lambda contra: 8.0000\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "kl_divergence[0]: 0.2733474490729295 kl_divergence[1]: 0.27165488085214545\n",
      "Epoch 17/100: Reconstruction loss: 1.0250, Adversarial loss: 2.8479, Contrastive loss: 4.7892, Covariance loss: 0.0000, lamdba recon: 6.0000, lambda adv: 4.0000, lambda cov: 0.0001, lambda contra: 8.0000\n"
     ]
    }
   ],
   "source": [
    "conf_matrix_cellfate, conf_matrix_tabular = data_size_study(dataset_size, train_images, train_labels, train_tracks, test_images, test_labels, test_tracks, x_train_full, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.52252252, 0.47747748],\n",
       "        [0.32142857, 0.67857143]],\n",
       "\n",
       "       [[0.54054054, 0.45945946],\n",
       "        [0.21428571, 0.78571429]],\n",
       "\n",
       "       [[0.63963964, 0.36036036],\n",
       "        [0.46428571, 0.53571429]],\n",
       "\n",
       "       [[0.57657658, 0.42342342],\n",
       "        [0.25      , 0.75      ]],\n",
       "\n",
       "       [[0.63063063, 0.36936937],\n",
       "        [0.25      , 0.75      ]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_cellfate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.63963964, 0.36036036],\n",
       "        [0.35714286, 0.64285714]],\n",
       "\n",
       "       [[0.56756757, 0.43243243],\n",
       "        [0.39285714, 0.60714286]],\n",
       "\n",
       "       [[0.57657658, 0.42342342],\n",
       "        [0.17857143, 0.82142857]],\n",
       "\n",
       "       [[0.62162162, 0.37837838],\n",
       "        [0.35714286, 0.64285714]],\n",
       "\n",
       "       [[0.6036036 , 0.3963964 ],\n",
       "        [0.32142857, 0.67857143]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
