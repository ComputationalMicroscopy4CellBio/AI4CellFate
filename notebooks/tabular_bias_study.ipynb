{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append(os.path.abspath(\"..\"))  #TODO: MAKE THE SRC PACKAGE WORK\n",
    "from src.training.new_optimised_train import train_autoencoder, train_cellfate\n",
    "from src.evaluation.evaluate import *\n",
    "from src.training.loss_functions import *\n",
    "from src.preprocessing.preprocessing_functions import *\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from src.models import Encoder, Decoder, Discriminator, mlp_classifier, complex_mlp_classifier\n",
    "from src.utils import *\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import tensorflow as tf\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.load('../data/labels/test_labels.npy')\n",
    "train_tracks = np.load(\"../data/tracks/train_tracks.npy\")\n",
    "train_labels = np.load(\"../data/labels/train_labels.npy\")\n",
    "test_tracks = np.load(\"../data/tracks/test_tracks.npy\")\n",
    "\n",
    "train_tracks_features = train_tracks[:, 0, 4:17] \n",
    "test_tracks_features = test_tracks[:, 0, 4:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1108, 13), (277, 13))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tracks_features.shape, test_tracks_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1 — Using features: [11  9]\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x2beaf4310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x2beaf4310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Run 2 — Using features: [ 8 10]\n",
      "Run 3 — Using features: [12 10]\n",
      "Run 4 — Using features: [9 1]\n",
      "Run 5 — Using features: [0 5]\n",
      "Run 6 — Using features: [8 9]\n",
      "Run 7 — Using features: [4 2]\n",
      "Run 8 — Using features: [11  2]\n",
      "Run 9 — Using features: [5 1]\n",
      "Run 10 — Using features: [11  9]\n",
      "Run 11 — Using features: [ 1 10]\n",
      "Run 12 — Using features: [10  1]\n",
      "Run 13 — Using features: [1 8]\n",
      "Run 14 — Using features: [7 9]\n",
      "Run 15 — Using features: [1 2]\n",
      "Run 16 — Using features: [11  1]\n",
      "Run 17 — Using features: [2 4]\n",
      "Run 18 — Using features: [9 5]\n",
      "Run 19 — Using features: [8 7]\n",
      "Run 20 — Using features: [9 8]\n",
      "Run 21 — Using features: [11  1]\n",
      "Run 22 — Using features: [5 1]\n",
      "Run 23 — Using features: [11  4]\n",
      "Run 24 — Using features: [11  6]\n",
      "Run 25 — Using features: [4 1]\n",
      "Run 26 — Using features: [4 1]\n",
      "Run 27 — Using features: [ 9 10]\n",
      "Run 28 — Using features: [5 9]\n",
      "Run 29 — Using features: [8 3]\n",
      "Run 30 — Using features: [7 5]\n",
      "\n",
      "Saved confusion matrices for 30 random feature combinations.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "\n",
    "# Define config\n",
    "config = {\n",
    "    'batch_size': 30,\n",
    "    'epochs': 50,\n",
    "    'learning_rate': 0.001,\n",
    "    'seed': 42,\n",
    "    'n_feature_pairs': 30  # number of random feature pairs to test\n",
    "}\n",
    "\n",
    "# Set seed\n",
    "tf.keras.utils.set_random_seed(config['seed'])\n",
    "np.random.seed(config['seed'])\n",
    "\n",
    "\n",
    "# Initialize container for confusion matrices\n",
    "conf_matrix_tabular = np.zeros((config['n_feature_pairs'], 2, 2))\n",
    "\n",
    "# Loop over N random feature combinations\n",
    "for i in range(config['n_feature_pairs']):\n",
    "    # Pick 2 random features\n",
    "    selected_features = np.random.choice(13, size=2, replace=False)\n",
    "    print(f\"Run {i+1} — Using features: {selected_features}\")\n",
    "\n",
    "    # Subset the data\n",
    "    X_train = train_tracks_features[:, selected_features]\n",
    "    X_test = test_tracks_features[:, selected_features]\n",
    "\n",
    "    # Train/val split\n",
    "    X_val, X_test_final, y_val, y_test_final = train_test_split(X_test, test_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Class weights\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    # Build model\n",
    "    classifier = complex_mlp_classifier(latent_dim=2)\n",
    "    classifier.compile(loss='sparse_categorical_crossentropy',\n",
    "                       optimizer=tf.keras.optimizers.Adam(learning_rate=config['learning_rate']),\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "    # Train\n",
    "    classifier.fit(X_train, train_labels,\n",
    "                   batch_size=config['batch_size'],\n",
    "                   epochs=config['epochs'],\n",
    "                   validation_data=(X_val, y_val),\n",
    "                   class_weight=class_weights,\n",
    "                   verbose=0)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = classifier.predict(X_test_final, verbose=0)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test_final, y_pred_classes)\n",
    "    cm_normalized = cm / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    conf_matrix_tabular[i] = cm_normalized\n",
    "\n",
    "# Save results\n",
    "np.save(\"confusion_matrices_random_feature_selection.npy\", conf_matrix_tabular)\n",
    "print(f\"\\nSaved confusion matrices for {config['n_feature_pairs']} random feature combinations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.5045045 , 0.4954955 ],\n",
       "        [0.21428571, 0.78571429]],\n",
       "\n",
       "       [[0.57657658, 0.42342342],\n",
       "        [0.42857143, 0.57142857]],\n",
       "\n",
       "       [[0.77477477, 0.22522523],\n",
       "        [0.67857143, 0.32142857]],\n",
       "\n",
       "       [[0.53153153, 0.46846847],\n",
       "        [0.28571429, 0.71428571]],\n",
       "\n",
       "       [[0.51351351, 0.48648649],\n",
       "        [0.28571429, 0.71428571]],\n",
       "\n",
       "       [[0.54054054, 0.45945946],\n",
       "        [0.21428571, 0.78571429]],\n",
       "\n",
       "       [[0.68468468, 0.31531532],\n",
       "        [0.67857143, 0.32142857]],\n",
       "\n",
       "       [[0.51351351, 0.48648649],\n",
       "        [0.32142857, 0.67857143]],\n",
       "\n",
       "       [[0.57657658, 0.42342342],\n",
       "        [0.39285714, 0.60714286]],\n",
       "\n",
       "       [[0.5045045 , 0.4954955 ],\n",
       "        [0.21428571, 0.78571429]],\n",
       "\n",
       "       [[0.73873874, 0.26126126],\n",
       "        [0.82142857, 0.17857143]],\n",
       "\n",
       "       [[0.59459459, 0.40540541],\n",
       "        [0.64285714, 0.35714286]],\n",
       "\n",
       "       [[0.56756757, 0.43243243],\n",
       "        [0.28571429, 0.71428571]],\n",
       "\n",
       "       [[0.47747748, 0.52252252],\n",
       "        [0.28571429, 0.71428571]],\n",
       "\n",
       "       [[0.47747748, 0.52252252],\n",
       "        [0.42857143, 0.57142857]],\n",
       "\n",
       "       [[0.54954955, 0.45045045],\n",
       "        [0.28571429, 0.71428571]],\n",
       "\n",
       "       [[0.65765766, 0.34234234],\n",
       "        [0.64285714, 0.35714286]],\n",
       "\n",
       "       [[0.43243243, 0.56756757],\n",
       "        [0.17857143, 0.82142857]],\n",
       "\n",
       "       [[0.48648649, 0.51351351],\n",
       "        [0.28571429, 0.71428571]],\n",
       "\n",
       "       [[0.47747748, 0.52252252],\n",
       "        [0.14285714, 0.85714286]],\n",
       "\n",
       "       [[0.54954955, 0.45045045],\n",
       "        [0.25      , 0.75      ]],\n",
       "\n",
       "       [[0.56756757, 0.43243243],\n",
       "        [0.42857143, 0.57142857]],\n",
       "\n",
       "       [[0.55855856, 0.44144144],\n",
       "        [0.28571429, 0.71428571]],\n",
       "\n",
       "       [[0.46846847, 0.53153153],\n",
       "        [0.17857143, 0.82142857]],\n",
       "\n",
       "       [[0.66666667, 0.33333333],\n",
       "        [0.67857143, 0.32142857]],\n",
       "\n",
       "       [[0.76576577, 0.23423423],\n",
       "        [0.78571429, 0.21428571]],\n",
       "\n",
       "       [[0.54054054, 0.45945946],\n",
       "        [0.32142857, 0.67857143]],\n",
       "\n",
       "       [[0.42342342, 0.57657658],\n",
       "        [0.17857143, 0.82142857]],\n",
       "\n",
       "       [[0.6036036 , 0.3963964 ],\n",
       "        [0.32142857, 0.67857143]],\n",
       "\n",
       "       [[0.52252252, 0.47747748],\n",
       "        [0.28571429, 0.71428571]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
